- Need to know what is in the training and what is in the test set. (IVAN)
- Predict in distribution and out of distribution images + better visualization. (KHANH)
- Cross-validation (UMER)
- Distribution of number of fascicles (CHECK postropcessing.py - KHANH)
- Distribution of area of fascicles (in the original shape) (CHECK postropcessing.py - KHANH)
- Augment with colour and fascicles (UMER)
- Augment with cropping (be careful) (UMER)
- Compute the distance between fascicles (IVAN) (QUITE DIFFICULT, NO PACKAGE FOUND)
- Morphological opening and closing (IVAN) -- DONE
- Watershed segmentation (IVAN) -- DONE
- Understand if there are specific metrics that might penalize errors on borders (IVAN) -- DONE
- https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_watershed.html (IVAN) -- DONE
- https://www.frontiersin.org/articles/10.3389/fnins.2021.685872/full
- https://www.nature.com/articles/s41596-020-0377-6


#######################################################################################
- Comparison of images area threshold
- Cross-loss visualizations for models 
- Custom metrics: IOU, combined_dice_loss, etc.
- Metrics to visualize: IoU, combined_dice_loss, DiceLoss, SparseCategoricalCrossEntropy
- Train adn visualize two-ways? (i.e. train with BCE_loss and visualize dice_loss and train with dice_loss and visualize BCE_loss)
- Distribution over training/validation set of the same metrics to visualize.





                                14/12/2021
#######################################################################################
Metrics: SPCC - dice loss - IoU - categorical accuracy - tversky loss - sparce mean IoU.
######################################################################################
- Visulaization tasks:
    + Original image: 2->4 augmented images
    + Remove post-processing distribution histograms
    + Image - Mask - Prediction - Overlay on mask - Numbers (Metrics)
    + Prediction - Prediction with watershed
- Data augmentation:
    + Clear description
    + Justification of parameters used
- Draw image of U_net X-Ception model architecture
- Remove save_best
- Find the optimized epochs, with visualization (e.g. save the model every 10 epochs and then compared the performace - unlabelled & validation)
- Check the formula of all loss functions, re-implement them, and retrain with optimized epochs
- Cross visualize (Metrics)
- Mention RMSProps vs Adam
- Post-processing:
    + Rewrite watershed - main purpose: visualize the separated regions
    + Delete small prediction with 0.01 quantized area
- Discussion:
    + Losses Discussion
    + Overfitting / Underfiting (epochs) - visualization on 40 vs 100 epochs

////////////NOTE: need to change the 1 - pred and 1 - mask

#############################################################################################
TODO KHANH:
- Compute the median of the areas in the masks (is the 0.5 quantile, you can add it to the prints of the stats)
- For the predictions:
	- go through all the regions:
		- if the area is above the 0.99 quantile of the areas colour in red
		- if the eccentricity is above the 0.99 quantile of the eccentricities or it is below the 0.01
		  quantile of the eccentricities, color in red
		- if you have colored a region in red, divide its area by the median and add it to the stats 
		  as multiple regions
- Compute the color histogram on the training set (google something) and compute it on the unlabelled set. Have it printed
and saved

TODO UMER:
	- README
	- necessary packages
	- comment the code